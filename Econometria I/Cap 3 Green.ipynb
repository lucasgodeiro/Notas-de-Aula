{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mínimos Quadrados \n",
    "\n",
    "\n",
    "## Introdução \n",
    "\n",
    "O capítulo 2 definiu o modelo de regressão linear como um conjunto de características da população que dependem de uma amostra observada dos dados. Para uma variedade de razões práticas e teóricas que exploraremos a medida que progredirmos para os próximos capítulos, o método de mínimos quadrados tem sido o mais popular. Entretanto, na maioria dos casos na qual outro método de estimacão é preferível, o MQO permanece como a abordagem referência, e frequentemente,  o método preferido é apenas um modificação do MQO. \n",
    "\n",
    "## Regressão de Mínimos Quadrados \n",
    "\n",
    "Os parâmetros desconhecidos da relação estocástica $y_{i} = \\mathbf{x'_{i} \\beta} + \\varepsilon_{i} $ são os objetos de estimação. É necessário distinguir entre as quantidades da população, tal qual $\\mathbf{\\beta} $ e $\\varepsilon_{i}  $ e as estimativas da amostra deles, denotadas por $\\mathbf{b}$ e $e_{i}$. A regressão da população é $E[y_{i} | \\mathbf{x_{i}} ] = \\mathbf{ x'_{i} \\beta} $, ao passo que nossa estimativas de  $E[y_{i} | \\mathbf{x_{i}} ]$ é denotada por: \n",
    "\n",
    "\\begin{equation}\n",
    "  \\hat{y}_{i} = \\mathbf{x'_{i} b}.\n",
    "\\end{equation} \n",
    "\n",
    "As perturbações associadas com a i-ésima observação é: \n",
    "\n",
    "$$\n",
    "\\varepsilon_{i} = y_{i} - \\mathbf{ x' \\beta }\n",
    ".$$\n",
    "\n",
    "Para qualquer valor de $\\mathbf{b} $, devemos estimar $\\varepsilon_{i} $ conhecido como o resíduo\n",
    "\n",
    "\n",
    "$$\n",
    "e_{i} = y_{i} - \\mathbf{ x' b }\n",
    ".$$\n",
    "\n",
    "A partir das definições, temos:\n",
    "\n",
    "$$\n",
    "y_{i} = \\mathbf{ x' \\beta } + \\varepsilon_{i} = \\mathbf{ x' b } + e_{i}\n",
    "$$\n",
    "\n",
    "Estas equações são resumidas pelas regressões na figura abaixo: \n",
    "\n",
    "<img src=\"images/fig31.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nesse caso, nosso problema será escolher um vetor $\\mathbf{b}$ tal que a linha ajustada $\\mathbf{x'_{i} b }$ seja o mais próximos possível dos dados. \n",
    "* Para tal objetivo, usaremos o método de mínimos quadrados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O vetor de coeficientes de Mínimos Quadrados\n",
    "\n",
    "O vetor de coeficientes que miniza a soma dos resíduos ao quadrado: \n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} e_{i0}^{2} = \\sum_{i=1}^{n} (y_{i} - \\mathbf{x'b_{0} }   )^{2} ,  \n",
    "$$\n",
    "\n",
    "onde denotamos $\\mathbf{b}_{0} $ para a escolha do vetor de coeficientes. Em termos matriciais, minimizando a soma dos quadrados dos resíduos reque escolher $\\mathbf{b}_{0} $ para: \n",
    "\n",
    "$$\n",
    "Min_{ \\mathbf{b}_{0} } S(\\mathbf{b}_{0} ) = \\mathbf{e}'_{0} \\mathbf{e}_{0} = ( \\mathbf{y} - \\mathbf{X} \\mathbf{b}_{0} )' ( \\mathbf{y} - \\mathbf{X} \\mathbf{b}_{0} ) $$\n",
    "\n",
    "expandindo temos: \n",
    "\n",
    "$$\n",
    "\\mathbf{e}'_{0} \\mathbf{e}_{0} = \\mathbf{y'} \\mathbf{y} - \\mathbf{b}_{0}' \\mathbf{X'} \\mathbf{y} - \\mathbf{y}' \\mathbf{X} \\mathbf{b}_{0}' + \\mathbf{b}_{0}' \\mathbf{X}' \\mathbf{X} \\mathbf{b}_{0}\n",
    "$$\n",
    "\n",
    "ou \n",
    "\n",
    "$$\n",
    "S(\\mathbf{b}_{0} ) = \\mathbf{y'} \\mathbf{y} - 2\\mathbf{y}' \\mathbf{X} \\mathbf{b}_{0} + \\mathbf{b}_{0}' \\mathbf{X}' \\mathbf{X} \\mathbf{b}_{0}\n",
    "$$\n",
    "\n",
    "A condição necessária para a achar o mínimo é: \n",
    "\n",
    "$$\n",
    "\\frac{ \\partial S(\\mathbf{b}_{0} ) }{ \\partial \\mathbf{b}_{0} } = -2 \\mathbf{X}' \\mathbf{y} + 2 \\mathbf{X}' \\mathbf{X} \\mathbf{b}_{0} = \\mathbf{0}.\n",
    "$$\n",
    "\n",
    "Seja $\\mathbf{b} $ a solução, após algumas manipulações, encontramos o  $ \\mathbf{b}$ que satisfaz as equações normais de MQO: \n",
    "\n",
    "$$\n",
    "\\mathbf{X}'\\mathbf{X} \\mathbf{b} = \\mathbf{X}' \\mathbf{y}\n",
    "$$\n",
    "\n",
    "Se existe a inversa de $\\mathbf{X}'\\mathbf{X} $, ou seja se a hipótese de posto completo é satisfeita, então a solução é:\n",
    "\n",
    "$$\n",
    " \\mathbf{b} =  (\\mathbf{X}'\\mathbf{X})^{-1} \\mathbf{X}' \\mathbf{y}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_31 <- read.csv(\"http://www.stern.nyu.edu/~wgreene/Text/Edition7/TableF3-1.csv\",header = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>YEAR</th><th scope=col>RealGNP</th><th scope=col>INVEST</th><th scope=col>GNPDefl</th><th scope=col>Interest</th><th scope=col>Infl</th><th scope=col>Trend</th><th scope=col>RealInv</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2000 </td><td>87.1 </td><td>2.034</td><td>81.9 </td><td>9.23 </td><td>3.4  </td><td>1    </td><td>2.484</td></tr>\n",
       "\t<tr><td>2001 </td><td>88.0 </td><td>1.929</td><td>83.8 </td><td>6.91 </td><td>1.6  </td><td>2    </td><td>2.311</td></tr>\n",
       "\t<tr><td>2002 </td><td>89.5 </td><td>1.925</td><td>85.0 </td><td>4.67 </td><td>2.4  </td><td>3    </td><td>2.265</td></tr>\n",
       "\t<tr><td>2003 </td><td>92.0 </td><td>2.028</td><td>86.7 </td><td>4.12 </td><td>1.9  </td><td>4    </td><td>2.339</td></tr>\n",
       "\t<tr><td>2004 </td><td>95.5 </td><td>2.277</td><td>89.1 </td><td>4.34 </td><td>3.3  </td><td>5    </td><td>2.556</td></tr>\n",
       "\t<tr><td>2005 </td><td>98.7 </td><td>2.527</td><td>91.9 </td><td>6.19 </td><td>3.4  </td><td>6    </td><td>2.750</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " YEAR & RealGNP & INVEST & GNPDefl & Interest & Infl & Trend & RealInv\\\\\n",
       "\\hline\n",
       "\t 2000  & 87.1  & 2.034 & 81.9  & 9.23  & 3.4   & 1     & 2.484\\\\\n",
       "\t 2001  & 88.0  & 1.929 & 83.8  & 6.91  & 1.6   & 2     & 2.311\\\\\n",
       "\t 2002  & 89.5  & 1.925 & 85.0  & 4.67  & 2.4   & 3     & 2.265\\\\\n",
       "\t 2003  & 92.0  & 2.028 & 86.7  & 4.12  & 1.9   & 4     & 2.339\\\\\n",
       "\t 2004  & 95.5  & 2.277 & 89.1  & 4.34  & 3.3   & 5     & 2.556\\\\\n",
       "\t 2005  & 98.7  & 2.527 & 91.9  & 6.19  & 3.4   & 6     & 2.750\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| YEAR | RealGNP | INVEST | GNPDefl | Interest | Infl | Trend | RealInv |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 2000  | 87.1  | 2.034 | 81.9  | 9.23  | 3.4   | 1     | 2.484 |\n",
       "| 2001  | 88.0  | 1.929 | 83.8  | 6.91  | 1.6   | 2     | 2.311 |\n",
       "| 2002  | 89.5  | 1.925 | 85.0  | 4.67  | 2.4   | 3     | 2.265 |\n",
       "| 2003  | 92.0  | 2.028 | 86.7  | 4.12  | 1.9   | 4     | 2.339 |\n",
       "| 2004  | 95.5  | 2.277 | 89.1  | 4.34  | 3.3   | 5     | 2.556 |\n",
       "| 2005  | 98.7  | 2.527 | 91.9  | 6.19  | 3.4   | 6     | 2.750 |\n",
       "\n"
      ],
      "text/plain": [
       "  YEAR RealGNP INVEST GNPDefl Interest Infl Trend RealInv\n",
       "1 2000 87.1    2.034  81.9    9.23     3.4  1     2.484  \n",
       "2 2001 88.0    1.929  83.8    6.91     1.6  2     2.311  \n",
       "3 2002 89.5    1.925  85.0    4.67     2.4  3     2.265  \n",
       "4 2003 92.0    2.028  86.7    4.12     1.9  4     2.339  \n",
       "5 2004 95.5    2.277  89.1    4.34     3.3  5     2.556  \n",
       "6 2005 98.7    2.527  91.9    6.19     3.4  6     2.750  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(table_31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'data.frame'"
      ],
      "text/latex": [
       "'data.frame'"
      ],
      "text/markdown": [
       "'data.frame'"
      ],
      "text/plain": [
       "[1] \"data.frame\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class(table_31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2.484</li>\n",
       "\t<li>2.311</li>\n",
       "\t<li>2.265</li>\n",
       "\t<li>2.339</li>\n",
       "\t<li>2.556</li>\n",
       "\t<li>2.75</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2.484\n",
       "\\item 2.311\n",
       "\\item 2.265\n",
       "\\item 2.339\n",
       "\\item 2.556\n",
       "\\item 2.75\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2.484\n",
       "2. 2.311\n",
       "3. 2.265\n",
       "4. 2.339\n",
       "5. 2.556\n",
       "6. 2.75\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2.484 2.311 2.265 2.339 2.556 2.750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y <- table_31$RealInv\n",
    "head(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1   </td><td>1   </td><td>87.1</td><td>9.23</td><td>3.4 </td></tr>\n",
       "\t<tr><td>1   </td><td>2   </td><td>88.0</td><td>6.91</td><td>1.6 </td></tr>\n",
       "\t<tr><td>1   </td><td>3   </td><td>89.5</td><td>4.67</td><td>2.4 </td></tr>\n",
       "\t<tr><td>1   </td><td>4   </td><td>92.0</td><td>4.12</td><td>1.9 </td></tr>\n",
       "\t<tr><td>1   </td><td>5   </td><td>95.5</td><td>4.34</td><td>3.3 </td></tr>\n",
       "\t<tr><td>1   </td><td>6   </td><td>98.7</td><td>6.19</td><td>3.4 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       "\t 1    & 1    & 87.1 & 9.23 & 3.4 \\\\\n",
       "\t 1    & 2    & 88.0 & 6.91 & 1.6 \\\\\n",
       "\t 1    & 3    & 89.5 & 4.67 & 2.4 \\\\\n",
       "\t 1    & 4    & 92.0 & 4.12 & 1.9 \\\\\n",
       "\t 1    & 5    & 95.5 & 4.34 & 3.3 \\\\\n",
       "\t 1    & 6    & 98.7 & 6.19 & 3.4 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1    | 1    | 87.1 | 9.23 | 3.4  |\n",
       "| 1    | 2    | 88.0 | 6.91 | 1.6  |\n",
       "| 1    | 3    | 89.5 | 4.67 | 2.4  |\n",
       "| 1    | 4    | 92.0 | 4.12 | 1.9  |\n",
       "| 1    | 5    | 95.5 | 4.34 | 3.3  |\n",
       "| 1    | 6    | 98.7 | 6.19 | 3.4  |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2] [,3] [,4] [,5]\n",
       "[1,] 1    1    87.1 9.23 3.4 \n",
       "[2,] 1    2    88.0 6.91 1.6 \n",
       "[3,] 1    3    89.5 4.67 2.4 \n",
       "[4,] 1    4    92.0 4.12 1.9 \n",
       "[5,] 1    5    95.5 4.34 3.3 \n",
       "[6,] 1    6    98.7 6.19 3.4 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X <- cbind(rep(1,length(y)), table_31$Trend , table_31$RealGNP , table_31$Interest, table_31$Infl)\n",
    "head(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             [,1]         [,2]         [,3]        [,4]         [,5]\n",
      "[1,] 182.96497706  4.214489471 -2.273589216  1.86498523 -0.020292918\n",
      "[2,]   4.21448947  0.109543966 -0.054281188  0.05778037  0.005507831\n",
      "[3,]  -2.27358922 -0.054281188  0.028591672 -0.02594739 -0.001320386\n",
      "[4,]   1.86498523  0.057780366 -0.025947395  0.05573051 -0.013407959\n",
      "[5,]  -0.02029292  0.005507831 -0.001320386 -0.01340796  0.077646710\n"
     ]
    }
   ],
   "source": [
    "####### Agora vamos computar os betas #############################\n",
    "X <- as.matrix(X)\n",
    "XX <- solve(t(X)%*%X)\n",
    "print(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [,1]\n",
      "[1,]   36.2920\n",
      "[2,]  288.6370\n",
      "[3,] 3612.0134\n",
      "[4,]  188.2441\n",
      "[5,]   82.7887\n"
     ]
    }
   ],
   "source": [
    "XY <- t(X) %*% y\n",
    "print(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            [,1]\n",
      "[1,] -6.21967209\n",
      "[2,] -0.16088526\n",
      "[3,]  0.09908417\n",
      "[4,]  0.02017157\n",
      "[5,] -0.01165919\n"
     ]
    }
   ],
   "source": [
    "b <- XX %*% XY\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = y ~ X1)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-0.23597 -0.07658  0.02551  0.07897  0.15815 \n",
       "\n",
       "Coefficients:\n",
       "                Estimate Std. Error t value Pr(>|t|)   \n",
       "(Intercept)     -6.21967    1.93045  -3.222  0.00915 **\n",
       "X1Trend         -0.16089    0.04724  -3.406  0.00670 **\n",
       "X1RealGNP        0.09908    0.02413   4.106  0.00212 **\n",
       "X1Interest Rate  0.02017    0.03369   0.599  0.56268   \n",
       "X1Infl          -0.01166    0.03977  -0.293  0.77538   \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.1427 on 10 degrees of freedom\n",
       "Multiple R-squared:  0.7878,\tAdjusted R-squared:  0.7029 \n",
       "F-statistic: 9.282 on 4 and 10 DF,  p-value: 0.002125\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X1 <- X[,-1]\n",
    "colnames(X1) <- c(\"Trend\", \"RealGNP\",\"Interest Rate\",\"Infl\")\n",
    "summary(lm(y ~ X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>15</li>\n",
       "\t<li>5</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 15\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 15\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 15  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspectos Algébricos da Solução do MQO\n",
    "\n",
    "As equações normais do MQO são: \n",
    "\n",
    "$$\n",
    "\\mathbf{X}'\\mathbf{X} \\mathbf{b} - \\mathbf{X}'\\mathbf{y} = - \\mathbf{X}'(\\mathbf{y} - \\mathbf{X} \\mathbf{b}) = -\\mathbf{X} \\mathbf{e} = \\mathbf{0}. \n",
    "$$\n",
    "\n",
    "Então, para cada coluna $\\mathbf{x}_{k} $ de $\\mathbf{X} $, $\\mathbf{x}'_{k} \\mathbf{e} = 0 $. A primeira coluna de $\\mathbf{X} $ é uma coluna com 1s, na qual denotamos $\\mathbf{i} $, então existem três implicações: \n",
    "\n",
    "1. A soma dos resíduos de mínimos quadrados é zero. Esta implicação vem de que $\\mathbf{x}'_{1} \\mathbf{e} = \\mathbf{i}'\\mathbf{e} = \\sum_{i} e_{i} = 0.  $\n",
    "\n",
    "2. A regressão no hiperplano passa pelo ponto da média dos dados . A primeira equação normal implica que $\\overline{y} = \\mathbf{\\overline{x}}'  \\mathbf{b} $.\n",
    "\n",
    "3. A média dos valores ajustados a partir da regressão é igual a média dos valores atuais(observados). Esta implicação vem do ponto 1, dado que os valores ajustados são justamente $\\mathbf{\\hat{y}} = \\mathbf{X} \\mathbf{b} $.\n",
    "\n",
    "È importante ressaltar que nenhum desses resultados se mantém no caso da regressão sem o termo constantes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              [,1]\n",
      " [1,]  0.087784108\n",
      " [2,]  0.012305113\n",
      " [3,]  0.033075777\n",
      " [4,]  0.025515386\n",
      " [5,]  0.068491177\n",
      " [6,]  0.070155623\n",
      " [7,] -0.004683308\n",
      " [8,] -0.116310293\n",
      " [9,] -0.184628696\n",
      "[10,] -0.235969790\n",
      "[11,] -0.138785972\n",
      "[12,] -0.036855018\n",
      "[13,]  0.158155464\n",
      "[14,]  0.105822717\n",
      "[15,]  0.155927711\n"
     ]
    }
   ],
   "source": [
    "### Calculando os resíduos \n",
    "e <- y - X%*%b\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calculando a soma dos resíduos \n",
    "round(sum(e),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeção \n",
    "\n",
    "O vetor dos resíduos de mínimos quadrados é: \n",
    "\n",
    "$$\n",
    "\\mathbf{e} = \\mathbf{y} - \\mathbf{X} \\mathbf{b} \n",
    "$$\n",
    "\n",
    "Inserindo o resultado na equação (3-6) para $\\mathbf{b} $ temos:\n",
    "\n",
    "$$\n",
    "\\mathbf{e} = \\mathbf{y} - \\mathbf{X}( \\mathbf{X'} \\mathbf{X})^{-1} \\mathbf{X'} \\mathbf{y} = (\\mathbf{I} -  \\mathbf{X}( \\mathbf{X'} \\mathbf{X})^{-1}\\mathbf{X'}  ) \\mathbf{y} = \\mathbf{M} \\mathbf{y}\n",
    "$$\n",
    "\n",
    "onde a matrix $n \\times n $  definida anteriormente é fundamental na análise de regressão. Podemos mostrar facilmente que $\\mathbf{M} $ é simétrica $(\\mathbf{M} = \\mathbf{M'} ) $ e idempotente $(\\mathbf{M} = \\mathbf{M}^{2})$. Na visão de (3-13) podemos interpretar $\\mathbf{M} $ como a matriz que produz o vetor dos resíduos de mínimos quadrados na regressão de $\\mathbf{y} $ sobre $\\mathbf{X} $ quando o mesmo pre multiplica qualquer vetor $\\mathbf{y} $. Temos que:\n",
    "\n",
    "$$\n",
    "\\mathbf{M}\\mathbf{X} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Uma forma de interpretar este resultado é que se $\\mathbf{X} $ é regredido sobre $\\mathbf{X} $, resultará em um perfeito ajuste e os resíduos serão zero. \n",
    "\n",
    "Finalmente (3-13) implica que $\\mathbf{y} = \\mathbf{X} \\mathbf{b} + \\mathbf{e} $, no qual é análogo a (2-3). A partição dos resultados de mínimos quadrados em duas partes, os valores ajustados $\\mathbf{\\hat{y} } = \\mathbf{X} \\mathbf{b} $ e os resíduos $\\mathbf{e} $ .  Desde que $\\mathbf{M} \\mathbf{X} = \\mathbf{0} $, estas duas partes são ortogonais. Agora, dado (3-13):\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{y}} = \\mathbf{y} - \\mathbf{e} = (\\mathbf{I} - \\mathbf{M}) \\mathbf{y} = \\mathbf{X} (\\mathbf{X'} \\mathbf{X} )^{-1} \\mathbf{X'} \\mathbf{y} = \\mathbf{P} \\mathbf{y}\n",
    "$$\n",
    "\n",
    "A matrix $\\mathbf{P} $ é a **matrix de projeção**. É a matriz formada a partir de $\\mathbf{X} $ tal que quando um vetor $\\mathbf{y} $ é pré muliplicado por $\\mathbf{P} $, o resultado é os valores ajustados na regressão de mínimos quadrados de $\\mathbf{y} $ sobre $\\mathbf{X}$. Esta é também a projeção do vetor $\\mathbf{y} $ no espaço da coluna de $\\mathbf{X} $. Multiplicando, encontraremos que, como $\\mathbf{M} $, $ \\mathbf{P}$ é simétrica e idempotente, ou seja: \n",
    "\n",
    "$$\n",
    "\\mathbf{P} \\mathbf{M} = \\mathbf{M} \\mathbf{P} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "como esperado de (3-15)\n",
    "\n",
    "$$\n",
    "\\mathbf{P} \\mathbf{X} = \\mathbf{X}\n",
    "$$\n",
    "\n",
    "Como uma consequência de (3-14) e (3-16), podemos ver que as partições de mínimos quadrados, o vetor $\\mathbf{y} $ em duas partes ortogonais:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{P} \\mathbf{y} + \\mathbf{M} \\mathbf{y} = \\mathbf{projecao} + \\mathbf{residuo} \n",
    "$$\n",
    "\n",
    "O resultado da seção 3.2 pode ser ilustrado na figura. A área em cinza do plano representa o espaço coluna de $\\mathbf{X}$. A projeção e os resíduos são as linhas pontilhadas ortogonais. Podemos ver também como o teorema de pitágoras funciona:\n",
    "\n",
    "<img src=\"images/fig32.png\">\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{y}' \\mathbf{y} = \\mathbf{y} \\mathbf{P}' \\mathbf{P}' \\mathbf{y} + \\mathbf{y}' \\mathbf{M}' \\mathbf{M} \\mathbf{y}  \\\\\n",
    " =  \\hat{\\mathbf{y}}' \\hat{\\mathbf{y}} + \\mathbf{e}' \\mathbf{e}.\n",
    "\\end{align} \n",
    "\n",
    "Depois de manipularmos as equações envolvendo os resultados de mínimos quadrados, a seguinte expressão equivalente para a soma dos quadrados dos resíduos é frequentemente útil, \n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{e}' \\mathbf{e} = \\mathbf{y}' \\mathbf{M}' \\mathbf{M} \\mathbf{y} = \\mathbf{y}' \\mathbf{M} \\mathbf{y} = \\mathbf{y}' \\mathbf{e} = \\mathbf{e}'\\mathbf{y} \\\\\n",
    "\\mathbf{e}' \\mathbf{e} = \\mathbf{y}' \\mathbf{y} - \\mathbf{b}' \\mathbf{X}' \\mathbf{X} \\mathbf{b} = \\mathbf{y}' \\mathbf{y} - \\mathbf{b}' \\mathbf{X}' \\mathbf{y} = \\mathbf{y}' \\mathbf{y} - \\mathbf{y}' \\mathbf{X} \\mathbf{b}. \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             [,1]        [,2]         [,3]        [,4]         [,5]\n",
      " [1,]  0.40773609 -0.34305985 -0.082645104  0.05055297  0.144114791\n",
      " [2,] -0.34305985  0.60688589 -0.175435506 -0.13510077  0.084278394\n",
      " [3,] -0.08264510 -0.17543551  0.732675960 -0.26061784 -0.212466777\n",
      " [4,]  0.05055297 -0.13510077 -0.260617836  0.69476655 -0.261075789\n",
      " [5,]  0.14411479  0.08427839 -0.212466777 -0.26107579  0.568686128\n",
      " [6,]  0.01237768  0.06822122 -0.071441824 -0.10183165 -0.271901020\n",
      " [7,] -0.13914235 -0.06060263  0.065994703  0.03816370 -0.009142162\n",
      " [8,] -0.16915243  0.10472115  0.103425940  0.12803502 -0.095140403\n",
      " [9,]  0.08941786 -0.16994855 -0.023370915 -0.13726572  0.020558709\n",
      "[10,] -0.08028943 -0.01657600 -0.104147768 -0.04525222 -0.066569490\n",
      "[11,] -0.01212869 -0.07541229 -0.065450786 -0.06127678  0.009812311\n",
      "[12,] -0.03740569  0.08124741 -0.033051879  0.02105769 -0.072794434\n",
      "[13,] -0.05787122 -0.03922040  0.003820826  0.03562682  0.086901232\n",
      "[14,]  0.07320450  0.03857306  0.042364155  0.01977439  0.022403618\n",
      "[15,]  0.14429088  0.03142888  0.080346811  0.01444364  0.052334893\n",
      "               [,6]         [,7]        [,8]         [,9]         [,10]\n",
      " [1,]  0.0123776795 -0.139142353 -0.16915243  0.089417864 -0.0802894273\n",
      " [2,]  0.0682212246 -0.060602632  0.10472115 -0.169948555 -0.0165760018\n",
      " [3,] -0.0714418244  0.065994703  0.10342594 -0.023370915 -0.1041477677\n",
      " [4,] -0.1018316529  0.038163697  0.12803502 -0.137265717 -0.0452522220\n",
      " [5,] -0.2719010203 -0.009142162 -0.09514040  0.020558709 -0.0665694899\n",
      " [6,]  0.7392088421 -0.161433279 -0.25273345 -0.020161889 -0.0005075336\n",
      " [7,] -0.1614332789  0.679815778 -0.29468815 -0.204287178  0.1112451962\n",
      " [8,] -0.2527334460 -0.294688146  0.51666058  0.067797039 -0.0014667196\n",
      " [9,] -0.0201618892 -0.204287178  0.06779704  0.496486165  0.1549926510\n",
      "[10,] -0.0005075336  0.111245196 -0.00146672  0.154992651  0.7477981916\n",
      "[11,]  0.0409830864  0.036986790  0.06797543 -0.074394578 -0.1412689977\n",
      "[12,] -0.0427077442  0.067601778 -0.10415000  0.185519738 -0.2522445262\n",
      "[13,]  0.0685061807  0.029895105  0.00646933 -0.008039986 -0.1840708245\n",
      "[14,] -0.0052948518 -0.048343620 -0.04769034 -0.113338126 -0.1013398172\n",
      "[15,] -0.0012837720 -0.112063675 -0.03006301 -0.263965222 -0.0203027114\n",
      "             [,11]       [,12]        [,13]        [,14]        [,15]\n",
      " [1,] -0.012128695 -0.03740569 -0.057871223  0.073204502  0.144290882\n",
      " [2,] -0.075412295  0.08124741 -0.039220398  0.038573061  0.031428883\n",
      " [3,] -0.065450786 -0.03305188  0.003820826  0.042364155  0.080346811\n",
      " [4,] -0.061276781  0.02105769  0.035626819  0.019774393  0.014443639\n",
      " [5,]  0.009812311 -0.07279443  0.086901232  0.022403618  0.052334893\n",
      " [6,]  0.040983086 -0.04270774  0.068506181 -0.005294852 -0.001283772\n",
      " [7,]  0.036986790  0.06760178  0.029895105 -0.048343620 -0.112063675\n",
      " [8,]  0.067975429 -0.10415000  0.006469330 -0.047690338 -0.030063010\n",
      " [9,] -0.074394578  0.18551974 -0.008039986 -0.113338126 -0.263965222\n",
      "[10,] -0.141268998 -0.25224453 -0.184070824 -0.101339817 -0.020302711\n",
      "[11,]  0.846313054 -0.12737046 -0.170983741 -0.137538514 -0.136245819\n",
      "[12,] -0.127370464  0.70683354 -0.195935919 -0.138041588 -0.058557910\n",
      "[13,] -0.170983741 -0.19593592  0.765989518 -0.179338984 -0.161747933\n",
      "[14,] -0.137538514 -0.13804159 -0.179338984  0.801682443 -0.227076331\n",
      "[15,] -0.136245819 -0.05855791 -0.161747933 -0.227076331  0.688461276\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>15</li>\n",
       "\t<li>15</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 15\n",
       "\\item 15\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 15\n",
       "2. 15\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 15 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calculando a matrix M \n",
    "n <- nrow(X)\n",
    "I <- diag(n)\n",
    "M <- I - X %*% solve((t(X) %*% X)) %*% t(X)\n",
    "print(M)\n",
    "dim(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>182.96497706</td><td> 4.214489471</td><td>-2.273589216</td><td> 1.86498523 </td><td>-0.020292918</td></tr>\n",
       "\t<tr><td>  4.21448947</td><td> 0.109543966</td><td>-0.054281188</td><td> 0.05778037 </td><td> 0.005507831</td></tr>\n",
       "\t<tr><td> -2.27358922</td><td>-0.054281188</td><td> 0.028591672</td><td>-0.02594739 </td><td>-0.001320386</td></tr>\n",
       "\t<tr><td>  1.86498523</td><td> 0.057780366</td><td>-0.025947395</td><td> 0.05573051 </td><td>-0.013407959</td></tr>\n",
       "\t<tr><td> -0.02029292</td><td> 0.005507831</td><td>-0.001320386</td><td>-0.01340796 </td><td> 0.077646710</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       "\t 182.96497706 &  4.214489471 & -2.273589216 &  1.86498523  & -0.020292918\\\\\n",
       "\t   4.21448947 &  0.109543966 & -0.054281188 &  0.05778037  &  0.005507831\\\\\n",
       "\t  -2.27358922 & -0.054281188 &  0.028591672 & -0.02594739  & -0.001320386\\\\\n",
       "\t   1.86498523 &  0.057780366 & -0.025947395 &  0.05573051  & -0.013407959\\\\\n",
       "\t  -0.02029292 &  0.005507831 & -0.001320386 & -0.01340796  &  0.077646710\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 182.96497706 |  4.214489471 | -2.273589216 |  1.86498523  | -0.020292918 |\n",
       "|   4.21448947 |  0.109543966 | -0.054281188 |  0.05778037  |  0.005507831 |\n",
       "|  -2.27358922 | -0.054281188 |  0.028591672 | -0.02594739  | -0.001320386 |\n",
       "|   1.86498523 |  0.057780366 | -0.025947395 |  0.05573051  | -0.013407959 |\n",
       "|  -0.02029292 |  0.005507831 | -0.001320386 | -0.01340796  |  0.077646710 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]         [,2]         [,3]         [,4]        [,5]        \n",
       "[1,] 182.96497706  4.214489471 -2.273589216  1.86498523 -0.020292918\n",
       "[2,]   4.21448947  0.109543966 -0.054281188  0.05778037  0.005507831\n",
       "[3,]  -2.27358922 -0.054281188  0.028591672 -0.02594739 -0.001320386\n",
       "[4,]   1.86498523  0.057780366 -0.025947395  0.05573051 -0.013407959\n",
       "[5,]  -0.02029292  0.005507831 -0.001320386 -0.01340796  0.077646710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solve((t(X) %*% X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>15</li>\n",
       "\t<li>15</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 15\n",
       "\\item 15\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 15\n",
       "2. 15\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 15 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(X %*% solve((t(X) %*% X)) %*% t(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gerar resíduo de outra maneira\n",
    "e1 <- M %*% y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "identical(round(e,4),round(e1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "| 0 | 0 | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "      [,1] [,2] [,3] [,4] [,5]\n",
       " [1,] 0    0    0    0    0   \n",
       " [2,] 0    0    0    0    0   \n",
       " [3,] 0    0    0    0    0   \n",
       " [4,] 0    0    0    0    0   \n",
       " [5,] 0    0    0    0    0   \n",
       " [6,] 0    0    0    0    0   \n",
       " [7,] 0    0    0    0    0   \n",
       " [8,] 0    0    0    0    0   \n",
       " [9,] 0    0    0    0    0   \n",
       "[10,] 0    0    0    0    0   \n",
       "[11,] 0    0    0    0    0   \n",
       "[12,] 0    0    0    0    0   \n",
       "[13,] 0    0    0    0    0   \n",
       "[14,] 0    0    0    0    0   \n",
       "[15,] 0    0    0    0    0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(M %*% X,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>15</li>\n",
       "\t<li>15</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 15\n",
       "\\item 15\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 15\n",
       "2. 15\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 15 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Calculando a Matriz P \n",
    "\n",
    "P <- X %*% solve((t(X) %*% X)) %*% t(X)\n",
    "dim(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [,1]\n",
      " [1,] 2.396216\n",
      " [2,] 2.298695\n",
      " [3,] 2.231924\n",
      " [4,] 2.313485\n",
      " [5,] 2.487509\n",
      " [6,] 2.679844\n",
      " [7,] 2.832683\n",
      " [8,] 2.833310\n",
      " [9,] 2.629629\n",
      "[10,] 2.113970\n",
      "[11,] 2.214786\n",
      "[12,] 2.204855\n",
      "[13,] 2.197845\n",
      "[14,] 2.376177\n",
      "[15,] 2.481072\n"
     ]
    }
   ],
   "source": [
    "### Calculando y_hat \n",
    "y_hat <- P%*%y\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Particionada e Regressão Parcial \n",
    "\n",
    "É comum espeficifar um modelo de regressão múltipla quando, de fato, centros de interesse em apenas uma ou um subconjunto de variáveis. Considere que equação dos rendimentos discutidas no exemplo 2.2. \n",
    "\n",
    "Embora estamos primariamente interessados na assosiação de rendimentos e educação, idade e, da necessidade, incluídas no modelo. A questão que consideramos aqui é qual computações são envolvidas em obter, em isolamento, os coeficientes de um subconjunto de variáveis na regressão múltipla. \n",
    "\n",
    "Suponha que a regressão envolve o conjunto de duas variáveis, $\\mathbf{X}_{1} $ e $\\mathbf{X}_{2} $. Então, \n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{ \\varepsilon } = \\mathbf{X_{1}} \\beta_{1} + \\mathbf{X_{2}} \\mathbf{ \\beta_{2} } + \\mathbf{ \\varepsilon }.\n",
    "$$\n",
    "\n",
    "Qual é a solução algébrica para o $\\mathbf{ \\beta_{2}} $ ? **As equações normais** são: \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "\\mathbf{X}_{1}' \\mathbf{X}_{1} & \\mathbf{X}_{1}' \\mathbf{X}_{2} \\\\\n",
    "\\mathbf{X}_{2}' \\mathbf{X}_{1} & \\mathbf{X}_{1}' \\mathbf{X}_{2}\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix} \n",
    "\\mathbf{b}_{1} \\\\\n",
    "\\mathbf{b}_{2} \n",
    "\\end{bmatrix}  =\n",
    "\\begin{bmatrix} \n",
    "\\mathbf{X}_{1}' \\mathbf{y} \\\\\n",
    "\\mathbf{X}_{2}' \\mathbf{y}\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "A solução pode se obtida usando a matriz inversa particionada. Alternativamente, (1) e (2) em (3-17) podem serem manipuladas diretamente para resolver para $\\mathbf{b}_{2} $. Primeiro resolvemos (1) para $\\mathbf{b}_{1}$: \n",
    "\n",
    "$$\n",
    "\\mathbf{b}_{1} = (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}' \\mathbf{y} - (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}' \\mathbf{X}_{2} \\mathbf{b}_{2} = (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}' (\\mathbf{y} - \\mathbf{X}_{2} \\mathbf{b}_{2} ) \n",
    "$$\n",
    "\n",
    "Esta solução afirma que $\\mathbf{b}_{1} $ é o conjunto de coeficientes na regressão de $\\mathbf{y} $ sobre $\\mathbf{X}_{1} $, menos um vetor de correção. Digredimos brevemente para examinar um resultado importante embutido em (3-18). Supunha que $\\mathbf{X}_{1}' \\mathbf{X}_{2} = \\mathbf{0} $. Então, $\\mathbf{b}_{1} = (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}' \\mathbf{y}  $, na qual é simplesmente o vetor de coeficientes na regressão de $\\mathbf{y} $ sobre $\\mathbf{X}_{1} $. O resultado geral é dado pelo seguinte teorema: \n",
    "\n",
    "**Teorema 3.1: Regressão Particionada Ortogonal**\n",
    "\n",
    "Em uma regressão linear múltipla de $\\mathbf{y}$ sobre dois conjuntos de variáveis $\\mathbf{X}_{1} $ e $\\mathbf{X}_{2} $, se os dois conjuntos de variáveis são ortogonais, então os vetores de coeficientes separados podem ser obtidos por regressões separadas de $\\mathbf{y} $ sobre $\\mathbf{X}_{1} $ sozinho e $\\mathbf{y} $ sobre $\\mathbf{X}_{2} $ sozinho. \n",
    "\n",
    "**Prova:** A hipótese do teorema é que $\\mathbf{X}_{1}' \\mathbf{X}_{2} = 0 $ nas equações normais em (3-17). Inserindo esta hipótese em (3-18) produz a solução imediata para $\\mathbf{b}_{1} = (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}' \\mathbf{y} $ e da mesma forma para $\\mathbf{b}_{2} $. \n",
    "\n",
    "$\\blacksquare$.\n",
    "\n",
    "Se dois conjuntos de variáveis $\\mathbf{X}_{1}$ e $\\mathbf{X}_{2} $ não são ortogonais, então a solução para $\\mathbf{b}_{1} $ e $\\mathbf{b}_{2} $ encontrada em (3-17) e (3-18) é mais complicada do que apenas uma simples regressões como no teorema 3.1. Uma solução mais geral é dada pelo seguinte teorema, que aparece em uma das primeiras edições da Econometrica: \n",
    "\n",
    "\n",
    "**Teorema 3.2: Teorema de Frisch-Waugh(1933)-Lovell(1963)** \n",
    "Em uma regressão linear de mínimos quadrados do vetor $\\mathbf{y}$ sobre dois conjuntos de variáveis $\\mathbf{X}_{1} $ e $\\mathbf{X}_{2} $, o subvetor $\\mathbf{b}_{2} $ é o conjunto de coeficientes obtido quando os resíduos da regressão de $\\mathbf{y} $ sobre $\\mathbf{X}_{1} $ sozinho são regredidos sobre o conjunto de resíduos obtidos quando cada coluna de $\\mathbf{X}_{2} $ é regredido sobre $\\mathbf{X}_{1} $. \n",
    "\n",
    "**Prova:** Para provar o teorema 3.2, começe com equação (2) de  (3-17), na qual: \n",
    "\n",
    "$$\n",
    "\\mathbf{X}_{2}' \\mathbf{X}_{1} \\mathbf{b}_{1} + \\mathbf{X}_{2}' \\mathbf{X}_{2} \\mathbf{b}_{2} = \\mathbf{X}_{2}' \\mathbf{y}\n",
    "$$\n",
    "\n",
    "Agora insira o resultado para $\\mathbf{b}_{1} $, que aparece que (3-18) neste resultado, o que produz: \n",
    "\n",
    "$$\n",
    "\\mathbf{X}_{2}' \\mathbf{X}_{1} (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}' \\mathbf{y} - \\mathbf{X}_{2}' \\mathbf{X}_{1} (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}' \\mathbf{X}_{2} \\mathbf{b}_{2}  + \\mathbf{X}_{2}' \\mathbf{X}_{2} \\mathbf{b}_{2} = \\mathbf{X}_{2}' \\mathbf{y}\n",
    "$$\n",
    "\n",
    "depois de organizarmos os termos temos a solução para $\\mathbf{b}_{2} $:\n",
    "\n",
    "\\begin{align} \n",
    "\\mathbf{b}_{2} = [\\mathbf{X}_{2}' (\\mathbf{I} - \\mathbf{X}_{1} (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{2}   ) \\mathbf{X}_{2}    ]^{-1}  [\\mathbf{X}_{2}' (\\mathbf{I} - \\mathbf{X}_{1} (\\mathbf{X}_{1}' \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}   )   \\mathbf{y}  ] \\\\\n",
    " = ( \\mathbf{X}_{2}' \\mathbf{M}_{1} \\mathbf{X}_{2}   )     ^{-1}  ( \\mathbf{X}_{2}' \\mathbf{M}_{1} \\mathbf{y}   ). \n",
    "\\end{align} \n",
    "\n",
    "A matriz que aparece entre parênteses é a matriz que produz os resíduos, visto em (3-14), neste caso definida para uma regressão sobre as colunas de $\\mathbf{X}_{1} $. Assim, $\\mathbf{M}_{1} \\mathbf{X}_{2} $ é a matriz dos resíduos; cada coluna de $\\mathbf{M}_{1} \\mathbf{X}_{2} $  é um vetor de resíduos na regressão da coluna correspondente de $\\mathbf{X}_{2} $ no conjunto de variáveis em $\\mathbf{X}_{1} $. Explorando este fato que $\\mathbf{M}_{1} $, assim como $\\mathbf{M} $, é simétrica e idempotente, podemos reescrever (3-19) como:\n",
    "\n",
    "$$\n",
    "\\mathbf{b}_{2} = ( \\mathbf{X}_{2}^{*'}\\mathbf{X}_{2}^{*} )^{-1} \\mathbf{X}_{2}^{\\ast '} \\mathbf{y}^{\\ast} ,\n",
    "$$\n",
    "\n",
    "onde: \n",
    "\n",
    "$$\n",
    "\\mathbf{X}_{2}^{*} =  \\mathbf{M}_{1} \\mathbf{X}_{2} \n",
    "$$\n",
    "\n",
    "e:\n",
    "\n",
    "$$\n",
    "\\mathbf{y}^{*} =  \\mathbf{M}_{1} \\mathbf{y} \n",
    "$$\n",
    "\n",
    "\n",
    "Este resultado é fundamental na análise de regressão. \n",
    "$\\blacksquare$\n",
    "\n",
    "Este processo é comumente chamado de \"parcializando\"  o efeito de $\\mathbf{X}_{1} $. Por esta razão, os coeficientes na regressão múltipla são frequentemente chamados de **coeficientes de regressão parcial**. A aplicação deste teorema para a computaçao de um simples coeficiente como sugerido no início desta seção é detalhado em seguida: \n",
    "\n",
    "Considere a regressão de $\\mathbf{y} $ sobre um conjunto de variáveis $\\mathbf{X} $ e uma variável adicional $\\mathbf{z} $. Denote os coeficientes como $\\mathbf{b}$ e $c $. \n",
    "\n",
    "** Corolário 3.2.1 Coeficientes da Regressão Individual **\n",
    "\n",
    "O coeficiente sobre $\\mathbf{z} $ em uma regressão múltipla de $\\mathbf{y} $ sobre $\\mathbf{W} = [\\mathbf{X},\\mathbf{z} ] $ é computado como $c = (\\mathbf{z}' \\mathbf{M} \\mathbf{z}  )^{-1} (\\mathbf{z}' \\mathbf{M} \\mathbf{y}  )  = ( \\mathbf{z}^{*'}\\mathbf{z}^{*} )^{-1} \\mathbf{z}^{\\ast '} \\mathbf{y}^{\\ast}  $ onde $\\mathbf{z}^{*}$ e $\\mathbf{y}^{\\ast}$ são os vetores de resíduos das regressões de $\\mathbf{z} $ e $\\mathbf{y}$ sobre $\\mathbf{X} $; $\\mathbf{z}^{*} = \\mathbf{M} \\mathbf{z} $  e $\\mathbf{y}^{*} = \\mathbf{M} \\mathbf{y} $. Onde $\\mathbf{M} $ é definido em (3-14). \n",
    "\n",
    "**Prova:** Esta é uma aplicação do teorema 3.2 na qual $\\mathbf{X}_{1} $ é $\\mathbf{X} $ e $\\mathbf{X}_{2} $ é $\\mathbf{z} $. \n",
    "$\\blacksquare $ \n",
    " \n",
    "\n",
    "Nos termos do exemplo 2.2, poderíamos obter o coeficiente da educação na regressão múltipla regredindo primeiro os rendimentos e a educação sobre a idade(ou idade e idade ao quadrado) e então usarmos os resíduos destas regressões em uma regressão simples. Em uma clássica aplicação desta última observação, Frisch e Waugh(1933) notaram que em uma configuração de série de tempo, os mesmos resultados são obtidos se a regressão foi estimada com a variável de tendência ou mesmo se os foi retirado primeiramente a tendência dos dados.\n",
    "\n",
    "Como uma aplicação destes resultados, considere o caso em que $\\mathbf{X}_{1} $ é $\\mathbf{i} $, o termo constantes que é uma coluna de 1s na primeira coluna de $\\mathbf{X} $. A solução para $b_{2} $ neste caso então é a inclinação na regressão que contém o termo constante. Usando o teorema 3.2 o vetor de resíduos para qualquer variável $\\mathbf{X}_{2} $ neste caso será: \n",
    "\n",
    "\\begin{align} \n",
    "\\mathbf{x}^{*} = \\mathbf{x} - \\mathbf{X}_{1} (\\mathbf{X}_{1}^{'} \\mathbf{X}_{1})^{-1} \\mathbf{X}_{1}^{'} \\mathbf{x}  \\\\ \n",
    " =  \\mathbf{x} - \\mathbf{i} (\\mathbf{i}^{'} \\mathbf{i})^{-1} \\mathbf{i}^{'} \\mathbf{x}  \\\\ \n",
    " =  \\mathbf{x} - \\mathbf{i} (1/n) \\mathbf{i}^{'} \\mathbf{x}  \\\\ \n",
    " = \\mathbf{x} - \\mathbf{i} \\mathbf{\\overline{x} } \\\\\n",
    " = \\mathbf{M}^{0} \\mathbf{x}.\n",
    " \\end{align} \n",
    " \n",
    " No apêndice A.5.4 temos a demonstração de como chegou-se a esse resultado. Para este caso, então, os resíduos são desvios da média amostral. Entretanto, cada coluna de $\\mathbf{M}_{1} \\mathbf{X}_{2} $ é a variável original, agora na forma de desvios em da média. Este resultado geral é resumido no seguinte corolário. \n",
    " \n",
    " **Corolário 3.2.2 Regressão com o termo constante**\n",
    " \n",
    " A inclinação em uma regressão múltipla que contém um termo constante são obtidas a partir da transformação dos dados em desvio em relação à média e então regredindo a variável $y$ na forma de desvio sobre as variáveis explicativas, também na forma de desvios. \n",
    " \n",
    " Tendo obtido os coeficientes de $\\mathbf{X}_{2} $, como podemos recuperar os coeficientes de $\\mathbf{X}_{1} $ (o termo constante)?  Uma forma é repetir o exercício enquanto invertemos o papeis de $\\mathbf{X}_{1} $ e $ \\mathbf{X}_{2}$. Mas existe uma forma mais fácil. Uma vez que já resolvemos para $\\mathbf{b}_{2} $. Entretanto, podemos usar (3-18) na solução para $\\mathbf{b}_{1} $. Se $ \\mathbf{X}_{1} $ é apenas uma coluna de 1s, então isto produz um resultado familia: \n",
    " \n",
    " $$\n",
    " b_{1} = \\overline{y} - \\overline{x}_{2} \\beta_{2} - \\cdots - \\overline{x}_{K} b_{K} \n",
    " $$\n",
    " \n",
    " Teorema 3.2 e os corolários 3.2.1 e 3.2.2 produzem uma interpretação útil da regressão particionada quando o modelo contém o termo constante. De acordo com o teorema 3.1, se as colunas de $\\mathbf{X} $ são ortogonais, ou seja, $\\mathbf{x}_{k}^{'} \\mathbf{x}_{m} $ para $k$ e $m$ colunas, então a os coeficientes da regressão  separada na regressão de $y$ sobre $\\mathbf{X}$ quando $\\mathbf{X} = [\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots, \\mathbf{x}_{K} ]  $ são simplesmente $\\mathbf{x}_{k}^{'} \\mathbf{y} / \\mathbf{x}_{k}^{'} \\mathbf{x}_{k}  $. Quando a regressão tem um termo constante, podemos computar os coeficientes da regressão múltipla pela regressão de $\\mathbf{y}$ em desvios em relação à média sobre as colunas de $\\mathbf{X} $ também em desvios em relação à média. Neste exemplo, a \"ortogonalidade\" das colunas significa que a covariância amostral(e correlações) das variáveis são zero. O resultado é outro teorema:     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
